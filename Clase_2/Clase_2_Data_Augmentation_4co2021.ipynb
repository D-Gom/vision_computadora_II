{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJWHjAloWHNM"
      },
      "source": [
        "# Data Augmentation\n",
        "\n",
        "El proceso de Data Augmentation consiste en realizar diversas transformaciones sobre los datos de entrada con el objetivo de aportar variabilidad e incrementar el tamaño de mi conjunto de datos, partiendo de los datos ya existentes y etiquetados. Dichas transformaciones puede ser, como vimos en teoria, de distintos tipos, sin embargo, es necesario tener en cuenta solo utilizar las que sean coherentes con el problema puntual sobre el que estamos trabajando.\n",
        "\n",
        "Para este ejercicio vamos a trabajar con un dataset de imágenes de perros y gatos, el cual contiene 4000 imagenes a color, 2000 de perros y 2000 de gatos. Dichas imágenes ya se encuentran divididas en 3 carpetas correspondientes a entrenamiento, validación y testeo con 2000, 1000 y 1000 imágenes en cada una, respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCxrrCdVSKet",
        "outputId": "8bc6989b-e79f-4ff6-9f65-ee09ec8694d5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchsummary\n",
        "!pip install torchmetrics\n",
        "import torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8oE5kx3X4jJ"
      },
      "source": [
        "Podemos descargar el dataset al entorno de trabajo, desde una carpea de en Drive a partir de utilizar el ID del archivo dentro de Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW1iKufTYHfi",
        "outputId": "cace764d-75a8-42fb-a0db-1b8103b4cd6f"
      },
      "outputs": [],
      "source": [
        "# https://drive.google.com/file/d/1QEsn1vs35pi3AFcMzSfmZtOdfXn2AqxG/view?usp=sharing\n",
        "# El ID sera: 1QEsn1vs35pi3AFcMzSfmZtOdfXn2AqxG\n",
        "!gdown --id 1QEsn1vs35pi3AFcMzSfmZtOdfXn2AqxG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fIHmgykYpSU"
      },
      "outputs": [],
      "source": [
        "!unzip /content/perros_y_gatos.zip > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T97WZY-xoLLT"
      },
      "source": [
        "## Visualización de los datos\n",
        "\n",
        "A partir de observar las distintas imágenes, podemos notar que no todas conservan las mismas dimensiones, por lo que será necesario realizar un redimensionamiento de forma tal que queden uniformes para un posible entrenamiento con capas convolucionales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "lQ1I4IJSnV6h",
        "outputId": "19cb6697-f1ca-49ac-cabe-8d3d3c7e9aa6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "image = mpimg.imread(\"train/cats/cat.108.jpg\")\n",
        "\n",
        "print(image.shape)\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8fegZFilttF"
      },
      "source": [
        "## Utilizar los datos\n",
        "\n",
        "Para consumir los datos con nuestro modelo vamos a utilizar objetos de la clase DataLoader con la diferencia, respecto al ejemplo con MNIST, que, en este caso, las imágenes no vienen incluidas dentro de `torchvision`. Entonces, para poder cargar imágenes propias utilizamos la clase [`ImageFolder`](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html?highlight=imagefolder#torchvision.datasets.ImageFolder), a la cual le pasamos el directorio donde se encuentran las imágenes a partir del cual infiere las clases dentro del dataset. Para mas información respecto a este punto ver [aquí](https://pytorch.org/vision/stable/generated/torchvision.datasets.DatasetFolder.html#torchvision.datasets.DatasetFolder)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL2JlRBBVVjS"
      },
      "outputs": [],
      "source": [
        "data_transforms = torchvision.transforms.Compose([\n",
        "                    torchvision.transforms.Resize(size=(150, 150)),\n",
        "                    torchvision.transforms.ToTensor()\n",
        "                  ])\n",
        "\n",
        "train_set = torchvision.datasets.ImageFolder(root='./train', transform=data_transforms)\n",
        "valid_set = torchvision.datasets.ImageFolder(root='./validation', transform=data_transforms)\n",
        "test_set = torchvision.datasets.ImageFolder(root='./test', transform=data_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d5qTnuXsixd"
      },
      "source": [
        "Ahora defino una red neuronal contemplando la opción de que, si existe una GPU, se mueva la red allí para optimizar el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WtAgm6kR_vw",
        "outputId": "380374b6-f547-4bb1-9507-adfc8ba8fcd0"
      },
      "outputs": [],
      "source": [
        "class ConvModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding='same')\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding='same')\n",
        "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding='same')\n",
        "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='same')\n",
        "        self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = torch.nn.Linear(in_features=10368, out_features=512)\n",
        "        self.fc2 = torch.nn.Linear(in_features=512, out_features=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))\n",
        "        x = self.pool3(torch.relu(self.conv3(x)))\n",
        "        x = self.pool4(torch.relu(self.conv4(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "conv_model = ConvModel()\n",
        "\n",
        "# Si hay una GPU disponible muevo el modelo allí para aprovechar ese recurso\n",
        "if torch.cuda.is_available():\n",
        "    conv_model.to(\"cuda\")\n",
        "\n",
        "torchsummary.summary(conv_model, (3, 150, 150))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWBR0JWXUoMj",
        "outputId": "c1940c85-e2f2-4567-d1d3-8189d47ffbad"
      },
      "outputs": [],
      "source": [
        "conv_model_optimizer = torch.optim.Adam(conv_model.parameters(), lr=0.001)\n",
        "\n",
        "conv_model_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "conv_model_accuracy = torchmetrics.Accuracy()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  conv_model_accuracy.to(\"cuda\")\n",
        "\n",
        "# Epocas de entrenamiento\n",
        "epochs = 20\n",
        "\n",
        "# Defino listas para realizar graficas de los resultados\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "\n",
        "## Defino mi loop de entrenamiento\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  epoch_train_loss = 0.0\n",
        "  epoch_train_accuracy = 0.0\n",
        "\n",
        "  for train_data, train_target in train_loader:\n",
        "\n",
        "    # Al igual que con el modelo, los datos también se deben pasar a la GPU\n",
        "    if torch.cuda.is_available():\n",
        "      train_data = train_data.to(\"cuda\")\n",
        "      train_target = train_target.to(\"cuda\")\n",
        "\n",
        "    conv_model_optimizer.zero_grad()\n",
        "    \n",
        "    output = conv_model(train_data)\n",
        "    \n",
        "    loss = conv_model_loss(output, train_target)\n",
        "    epoch_train_loss += loss.item()\n",
        "    loss.backward()\n",
        "    \n",
        "    conv_model_optimizer.step()\n",
        "\n",
        "    accuracy = conv_model_accuracy(output, train_target)\n",
        "    epoch_train_accuracy += accuracy.item()\n",
        "\n",
        "  # Calculo la media de error y accuracy para la epoca de entrenamiento.\n",
        "  # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n",
        "  epoch_train_loss = epoch_train_loss / len(train_loader)\n",
        "  epoch_train_accuracy = epoch_train_accuracy / len(train_loader)\n",
        "  train_loss.append(epoch_train_loss)\n",
        "  train_acc.append(epoch_train_accuracy)\n",
        "\n",
        "  # Realizo el paso de validación computando error y accuracy, y\n",
        "  # almacenando los valores para imprimirlos y graficarlos\n",
        "  epoch_valid_loss = 0.0\n",
        "  epoch_valid_accuracy = 0.0\n",
        "\n",
        "  for valid_data, valid_target in valid_loader:\n",
        "    if torch.cuda.is_available():\n",
        "      valid_data = valid_data.to(\"cuda\")\n",
        "      valid_target = valid_target.to(\"cuda\")\n",
        "\n",
        "    output = conv_model(valid_data)\n",
        "    epoch_valid_loss += conv_model_loss(output, valid_target).item()\n",
        "    epoch_valid_accuracy += conv_model_accuracy(output, valid_target).item()\n",
        "      \n",
        "  epoch_valid_loss = epoch_valid_loss / len(valid_loader)\n",
        "  epoch_valid_accuracy = epoch_valid_accuracy / len(valid_loader)\n",
        "  valid_loss.append(epoch_valid_loss)\n",
        "  valid_acc.append(epoch_valid_accuracy)\n",
        "\n",
        "  print(\"Epoch: {}/{} - Train loss {:.6f} - Train Accuracy {:.6f} - Valid Loss {:.6f} - Valid Accuracy {:.6f}\".format(\n",
        "      epoch+1, epochs, epoch_train_loss, epoch_train_accuracy, epoch_valid_loss, epoch_valid_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-fuvze5dgm7"
      },
      "source": [
        "Realizo gráficas del resultado del entrenamiento para visualizar el comportamiento de las métricas a lo largo de las epocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "lBFgC18faq-q",
        "outputId": "8dfbc55c-97f1-49ba-8362-4184d6bdbf3e"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
        "\n",
        "axs[0].plot(train_loss[1:]) \n",
        "axs[0].plot(valid_loss[1:]) \n",
        "axs[0].title.set_text('Error de Entrenamiento vs Validación') \n",
        "axs[0].legend(['Train', 'Valid'])  \n",
        "\n",
        "axs[1].plot(train_acc) \n",
        "axs[1].plot(valid_acc) \n",
        "axs[1].title.set_text('Accuracy de Entrenamiento vs Validación') \n",
        "axs[1].legend(['Train', 'Valid'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xESj7o4YBl5"
      },
      "source": [
        "Su puede observar una clara tendencia al sobreentrenamiento del modelo, el cual es debido a, entre otras cosas, la poca cantidad de datos de entrenamiento utilizados.\n",
        "\n",
        "Si evaluo el modelo con el conjunto de testeo los resultados son:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dQWDhIKbb0y",
        "outputId": "926dc605-6c1e-40bf-d0c9-09538215c1b0"
      },
      "outputs": [],
      "source": [
        "# Realizo el paso de evaluación computando error y accuracy\n",
        "test_loss = 0.0\n",
        "test_accuracy = 0.0\n",
        "\n",
        "for test_data, test_target in test_loader:\n",
        "  if torch.cuda.is_available():\n",
        "        test_data, test_target = test_data.cuda(), test_target.cuda()\n",
        "  output = conv_model(test_data)\n",
        "  test_loss += conv_model_loss(output, test_target).item()\n",
        "  test_accuracy += conv_model_accuracy(output, test_target).item()\n",
        "\n",
        "test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = test_accuracy / len(test_loader)\n",
        "\n",
        "print(\"El modelo logro un error de {:.6f} y una accuracy de {:.6f}\".format(test_loss, test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xrQcjrmARne"
      },
      "source": [
        "---\n",
        "## Aplicar Data Augmentation\n",
        "\n",
        "Para aplicar Data Augmentation sobre los datos vamos a utilizar la misma composición de transformaciones que ya veniamos utilizando. Allí podemos agregar una serie de funciones listadas [`aquí`](https://pytorch.org/vision/stable/transforms.html). Para ver ejemplos de dichas transformaciones ver [este](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py) link."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1Wv3Ozhd2DC"
      },
      "outputs": [],
      "source": [
        "aud_data_transforms = torchvision.transforms.Compose([\n",
        "                        torchvision.transforms.Resize(size=(150, 150)),\n",
        "                        torchvision.transforms.RandomHorizontalFlip(0.5),\n",
        "                        torchvision.transforms.RandomResizedCrop(size=(150, 150), scale=(0.5, 1.0)),\n",
        "                        torchvision.transforms.ColorJitter(saturation=0.05, hue=0.05),\n",
        "                        torchvision.transforms.ToTensor(),\n",
        "                      ])\n",
        "\n",
        "aug_train_set = torchvision.datasets.ImageFolder(root='./train', transform=aud_data_transforms)\n",
        "aug_valid_set = torchvision.datasets.ImageFolder(root='./validation', transform=aud_data_transforms)\n",
        "\n",
        "aug_train_loader = torch.utils.data.DataLoader(aug_train_set, batch_size=32, shuffle=True)\n",
        "aug_valid_loader = torch.utils.data.DataLoader(aug_valid_set, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYOyV-AbeYhS"
      },
      "source": [
        "Podemos visualizar el resultado de aplicar dichas transformaciones sobre las imágenes de nuestro dataset. Aquí el metodo [`permute`](https://pytorch.org/docs/stable/generated/torch.permute.html#torch.permute) nos permite reordenar las dimensiones del tensor de (3, 150, 150) a (150, 150, 3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "mMzH_oqQf1wD",
        "outputId": "73388f3b-de29-48c0-d743-263a7f858fab"
      },
      "outputs": [],
      "source": [
        "fig, rows = plt.subplots(nrows=1, ncols=4, figsize=(18, 18))\n",
        "\n",
        "for id, row in enumerate(rows):\n",
        "    row.imshow(aug_train_set[id][0].permute(1, 2, 0))\n",
        "    row.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ljmppdfe10k"
      },
      "source": [
        "Si ahora, repito el proceso de entrenamiento, utilizando la misma arquitectura de red neuronal del caso anterior, pero pasandole datos sobre los que realizo las perturbaciones antes definidas, mi entrenamiento deberia ser más estable aunque un poco mas lento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBG_fRkonCJW",
        "outputId": "6016d4d5-5905-4267-c2dc-6386461b3e72"
      },
      "outputs": [],
      "source": [
        "aug_conv_model = ConvModel()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  aug_conv_model = aug_conv_model.to(\"cuda\")\n",
        "\n",
        "aug_conv_model_optimizer = torch.optim.Adam(aug_conv_model.parameters(), lr=0.0001)\n",
        "\n",
        "aug_conv_model_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "aug_conv_model_accuracy = torchmetrics.Accuracy()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  aug_conv_model_accuracy = aug_conv_model_accuracy.to(\"cuda\")\n",
        "\n",
        "# Epocas de entrenamiento\n",
        "epochs = 40\n",
        "\n",
        "# Defino listas para realizar graficas de los resultados\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "\n",
        "## Defino mi loop de entrenamiento\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  epoch_train_loss = 0.0\n",
        "  epoch_train_accuracy = 0.0\n",
        "\n",
        "  for aug_train_data, aug_train_target in aug_train_loader:\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      aug_train_data = aug_train_data.to(\"cuda\")\n",
        "      aug_train_target = aug_train_target.to(\"cuda\")\n",
        "\n",
        "    aug_conv_model_optimizer.zero_grad()\n",
        "    \n",
        "    aug_output = aug_conv_model(aug_train_data)\n",
        "    \n",
        "    aug_loss = aug_conv_model_loss(aug_output, aug_train_target)\n",
        "    epoch_train_loss += aug_loss.item()\n",
        "    aug_loss.backward()\n",
        "    \n",
        "    aug_conv_model_optimizer.step()\n",
        "    accuracy = aug_conv_model_accuracy(aug_output, aug_train_target)\n",
        "    epoch_train_accuracy += accuracy.item()\n",
        "\n",
        "  # Calculo la media de error y accuracy para la epoca de entrenamiento.\n",
        "  # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n",
        "  epoch_train_loss = epoch_train_loss / len(aug_train_loader)\n",
        "  epoch_train_accuracy = epoch_train_accuracy / len(aug_train_loader)\n",
        "  train_loss.append(epoch_train_loss)\n",
        "  train_acc.append(epoch_train_accuracy)\n",
        "\n",
        "  # Realizo el paso de validación computando error y accuracy, y\n",
        "  # almacenando los valores para imprimirlos y graficarlos\n",
        "  epoch_valid_loss = 0.0\n",
        "  epoch_valid_accuracy = 0.0\n",
        "\n",
        "  for aug_valid_data, aug_valid_target in aug_valid_loader:\n",
        "    if torch.cuda.is_available():\n",
        "      aug_valid_data = aug_valid_data.to(\"cuda\")\n",
        "      aug_valid_target = aug_valid_target.to(\"cuda\")\n",
        "\n",
        "    aug_output = aug_conv_model(aug_valid_data)\n",
        "    epoch_valid_loss += aug_conv_model_loss(aug_output, aug_valid_target).item()\n",
        "    epoch_valid_accuracy += aug_conv_model_accuracy(aug_output, aug_valid_target).item()\n",
        "      \n",
        "  epoch_valid_loss = epoch_valid_loss / len(aug_valid_loader)\n",
        "  epoch_valid_accuracy = epoch_valid_accuracy / len(aug_valid_loader)\n",
        "  valid_loss.append(epoch_valid_loss)\n",
        "  valid_acc.append(epoch_valid_accuracy)\n",
        "\n",
        "  print(\"Epoch: {}/{} - Train loss {:.6f} - Train Accuracy {:.6f} - Valid Loss {:.6f} - Valid Accuracy {:.6f}\".format(\n",
        "      epoch+1, epochs, epoch_train_loss, epoch_train_accuracy, epoch_valid_loss, epoch_valid_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "IabLfLVZnfvT",
        "outputId": "d9f5d6c5-af8e-494c-eaa2-3e280587da45"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
        "\n",
        "axs[0].plot(train_loss[1:]) \n",
        "axs[0].plot(valid_loss[1:]) \n",
        "axs[0].title.set_text('Error de Entrenamiento vs Validación') \n",
        "axs[0].legend(['Train', 'Valid'])  \n",
        "\n",
        "axs[1].plot(train_acc) \n",
        "axs[1].plot(valid_acc) \n",
        "axs[1].title.set_text('Accuracy de Entrenamiento vs Validación') \n",
        "axs[1].legend(['Train', 'Valid'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMgnXm-HXo30"
      },
      "source": [
        "Luego de entrenar, evaluo el modelo con los datos de testeo sin aplicarles data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcorUC5QLqIw",
        "outputId": "4235e92b-f64f-46a0-cd97-96e74ca501c7"
      },
      "outputs": [],
      "source": [
        "# Realizo el paso de evaluación computando error y accuracy\n",
        "test_loss = 0.0\n",
        "test_accuracy = 0.0\n",
        "\n",
        "for test_data, test_target in test_loader:\n",
        "  if torch.cuda.is_available():\n",
        "        test_data, test_target = test_data.cuda(), test_target.cuda()\n",
        "  output = aug_conv_model(test_data)\n",
        "  test_loss += aug_conv_model_loss(output, test_target).item()\n",
        "  test_accuracy += aug_conv_model_accuracy(output, test_target).item()\n",
        "\n",
        "test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = test_accuracy / len(test_loader)\n",
        "\n",
        "print(\"El modelo logro un error de {:.6f} y una accuracy de {:.6f}\".format(test_loss, test_accuracy))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Clase 2 - Data Augmentation - 4co2021.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
